model: Qwen/Qwen3-8B
# model: meta-llama/Llama-3.1-8B-Instruct

chat_template: |
  {% for message in messages %}
  {% if loop.first and messages[0]['role'] != 'system' %}
      {{ '<|im_start|>system\nYou are given a problem.\n Think about the problem and provide your working out.\n Provide step-by-step reasoning followed by your final answer.\nPlace reasoning between <think> and </think>.\n<|im_end|>\n' }}
  {% endif %}

  {% if message['role'] == 'assistant' %}
      {{ '<|im_start|>assistant\n' }}
      {% generation %}{{ message['content'] }}{% endgeneration %}
      {{ '<|im_end|>\n' }}
  {% else %}
      {{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>\n' }}
  {% endif %}

  {% endfor %}

  {% if add_generation_prompt %}
      {{ '<|im_start|>assistant\n' }}{% generation %}{% endgeneration %}
  {% endif %}

tokenizer_additional_special_tokens:
  - "<think>"
  - "</think>"