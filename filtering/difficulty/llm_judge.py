import csv, json, openai
import re
import os
import argparse
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def llm_judge_prompt(question, answers, solution):
    return f"""
ë‹¹ì‹ ì€ 'ë²•ë¥  MCQA ë°ì´í„°ì…‹ ê²€ì¦ ì „ë¬¸ê°€(Legal MCQA Evaluator)'ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸í•­ì˜ í’ˆì§ˆì„ ë²•ë¦¬ì Â·ë…¼ë¦¬ì ìœ¼ë¡œ ì¢…í•© í‰ê°€í•˜ì„¸ìš”.

### [ì§ˆë¬¸]
{question}

### [ì„ íƒì§€]
1. {answers[0]}
2. {answers[1]}
3. {answers[2]}
4. {answers[3]}
5. {answers[4]}

### [ì •ë‹µ]
{solution}

ì •ë‹µì´ ì œê³µë˜ì—ˆìœ¼ë¯€ë¡œ, ì•„ë˜ í‰ê°€ ì „ë°˜ì—ì„œ ì œê³µëœ ì •ë‹µì„ ê¸°ì¤€(anchor)ìœ¼ë¡œ ì‚¼ì•„ ë¶„ì„í•˜ê³  ì˜¤ë‹µê³¼ì˜ êµ¬ë³„ì´ ëª…í™•í•œì§€ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œë§Œ í‰ê°€ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì‹­ì‹œì˜¤:

## 1. ì„ íƒì§€ ê°„ ì˜ë¯¸ì  ì¤‘ë³µ ì—¬ë¶€ (Semantic Redundancy)
- ì™„ì „ ë™ì¼ì— ì¤€í•˜ëŠ” ì¤‘ë³µë§Œ ê¸°ë¡

## 2. í™˜ê° ë°œìƒ ì—¬ë¶€ (Hallucination Detection)
ë‹¤ìŒ ê¸°ì¤€ì¼ ë•Œë§Œ 'í™˜ê°'ìœ¼ë¡œ íŒì •í•˜ë©°, ë‹¨ìˆœ ì˜¤ë‹µê³¼ ì—„ê²©íˆ êµ¬ë¶„í•©ë‹ˆë‹¤.

í™˜ê° íŒì •ì€ "ëª…ë°±í•œ í—ˆêµ¬ ê·¼ê±°"ê°€ ì¸ìš©ë  ë•Œì—ë§Œ í—ˆìš©í•©ë‹ˆë‹¤. ê·¼ê±°ë¥¼ ì •í™•íˆ ì œì‹œí•  ìˆ˜ ì—†ìœ¼ë©´ í™˜ê°ìœ¼ë¡œ ê¸°ë¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

- í™˜ê°ì˜ ì •ì˜(í—ˆêµ¬ ì°½ì‘):
  - (a) ì‹¤ì œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°í•­ë²ˆí˜¸Â·ë²• ì¡°ë¬¸Â·íŒë¡€ëª…ì„ ì°½ì‘í•´ ë‹¨ì •ì ìœ¼ë¡œ ì œì‹œ
  - (b) í•´ë‹¹ ë¶„ì•¼ì—ì„œ ìŠ¹ì¸ëœ ë²•ë¦¬Â·íŒë¡€ì™€ ì •ë©´ìœ¼ë¡œ ì¶©ëŒí•˜ëŠ” 'í—ˆêµ¬ì  ê²°ë¡ 'ì„ ì‚¬ì‹¤ì²˜ëŸ¼ ë‹¨ì •(ë‹¨, ë‹¨ìˆœí•œ ì˜¤í•´Â·ì˜¤íŒÂ·ë‹¤ìˆ˜ì„¤/ì†Œìˆ˜ì„¤ ëŒ€ë¦½ì€ ì—¬ê¸°ì— í•´ë‹¹í•˜ì§€ ì•ŠìŒ)
  - (c) ë²•ì¡°ê³„ì—ì„œ í†µìš©ë˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ë²•ë¦¬/ìš©ì–´ë¥¼ ì°½ì‘í•˜ì—¬ ì‚¬ì‹¤ì²˜ëŸ¼ ë‹¨ì •

- í™˜ê° ì•„ë‹˜(ì˜¤ë‹µ/ë‹¤ë¥¸ ìœ í˜•):
  - ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë²•ë ¹Â·íŒë¡€ì— ëŒ€í•œ ì˜¤í•´Â·ê³¼ì¥Â·ë¶€ë¶„ì  í‹€ë¦¼, íŒë¡€ íƒœë„ì˜ ë‹¨ìˆœ ì˜¤íŒÂ·ì˜ëª»ëœ ì¼ë°˜í™”
  - ì •ë‹µì´ ì•„ë‹Œ ì„ íƒì§€, ë…¼ì¦ì´ ë¶€ì¡±í•œ ì£¼ì¥, ë…¼ë¦¬ì  ë¹„ì•½ì€ 'SemanticDistance' ë˜ëŠ” 'LogicalGap'ìœ¼ë¡œë§Œ ê³ ë ¤í•˜ê±°ë‚˜ í•„ìš” ì‹œ ë¯¸ê¸°ë¡

- í™˜ê° ì¦ê±° ì œì‹œ ì˜ë¬´(Evidence Rule): 'Hallucination' ìœ í˜•ì„ ê¸°ë¡í•˜ë ¤ë©´ commentì— ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
  - [í—ˆêµ¬ ìš”ì†Œ ì¸ìš©] ì •í™•í•œ í—ˆêµ¬ ì¡°í•­ë²ˆí˜¸/íŒë¡€ëª…/ìš©ì–´(ì˜ˆ: "í˜•ë²• ì œ999ì¡°"ì™€ ê°™ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°ë¬¸, ì‹¤ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ê±´ë²ˆí˜¸Â·íŒë¡€ëª…)
  - [ì§ì ‘ ëª¨ìˆœ ì¸ìš©] íŠ¹ì • í™•ë¦½ íŒë¡€(ì‚¬ê±´ë²ˆí˜¸/ì„ ê³ ì—°ì›”ì¼/ë²•ì›) ë˜ëŠ” ë²• ì¡°ë¬¸ê³¼ ì–´ê¸‹ë‚˜ëŠ” ë¬¸êµ¬ë¥¼ ì›ë¬¸ ìˆ˜ì¤€ì—ì„œ ì¸ìš©í•œ ë’¤, ì™œ 'í—ˆêµ¬ì  ê²°ë¡ 'ì— í•´ë‹¹í•˜ëŠ”ì§€ ë‹¨ì •ì ìœ¼ë¡œ ì„¤ëª…
  - ìœ„ë¥¼ commentì— ì •í™•íˆ ì¸ìš©í•  ìˆ˜ ì—†ìœ¼ë©´ 'Hallucination'ìœ¼ë¡œ ê¸°ë¡í•˜ì§€ ë§ê³ , í•„ìš” ì‹œ ë‹¤ë¥¸ ìœ í˜•ìœ¼ë¡œë§Œ ê¸°ë¡

ì£¼ì˜: ìœ„ (a)~(c) ìš”ê±´ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ 'í™˜ê°'ìœ¼ë¡œ ê¸°ë¡í•˜ì§€ ë§ˆì„¸ìš”. íŠ¹íˆ ë³€í˜¸ì‚¬ì‹œí—˜ ë¬¸í•­ì—ì„œ í•´ì„ìƒ í‹€ë¦¼Â·ë…¼ì¦ ë¶€ì¡±Â·ê³¼ì¥ëœ ì§„ìˆ ì€ í™˜ê°ì´ ì•„ë‹™ë‹ˆë‹¤.

## 3. ë¬¸í•­ êµ¬ì¡° ë° ì¼ê´€ì„± (Structural Coherence)
- ë¬¸í•­ì´ ì‚¬ì‹¤ìƒ ì´í•´ ë¶ˆê°€ëŠ¥í•œ ìˆ˜ì¤€ì¼ ë•Œë§Œ ê¸°ë¡
- ë¬¸í•­ ìœ í˜• ì£¼ì˜: ã„±, ã„´, ã„· ë“±ì˜ ì§„ìˆ  ì¡°í•©(ì˜ˆ: "ã„±, ã„´" / "ã„±, ã„·, ã„¹")ì„ ì •ë‹µìœ¼ë¡œ ê³ ë¥´ëŠ” ë³µìˆ˜ì •ë‹µí˜•ì¼ ìˆ˜ ìˆìŒ
- ë³µìˆ˜ì •ë‹µí˜•Â·ì¡°í•©í˜•ì´ë¼ëŠ” ì´ìœ ë§Œìœ¼ë¡œ êµ¬ì¡° ë¬¸ì œë¡œ ê¸°ë¡í•˜ì§€ ë§ ê²ƒ(ì„ ì§€ ê²°í•© ê·œì¹™ì´ ëª…í™•í•˜ë©´ ì •ìƒ êµ¬ì¡°)

## 4. ì¶”ê°€ ê²€ì¦ í•­ëª© (Additional Validation)
- â€˜ë„ˆë¬´ ëª…ë°±í•œ ë¶€ì •í˜• ì§„ìˆ â€™ë§Œ ê¸°ë¡
- â€˜ë‹¨ìˆœ ì‚¬ì‹¤ì„œìˆ â€™ë¡œ ë²•ì  ìŸì ì„ ìœ ë„í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ë§Œ ê¸°ë¡
- ì •ë‹µê³¼ ì˜¤ë‹µ ê°„ ì˜ë¯¸ì  ê±°ë¦¬ê°€ ì§€ë‚˜ì¹˜ê²Œ í° ê²½ìš°ë§Œ ê¸°ë¡
- ì •ë‹µì´ ì§€ë¬¸ ë‚´ì—ì„œ ë…¼ë¦¬ì  ê·¼ê±° ì—†ì´ ë‹¨ë…ìœ¼ë¡œ ë“±ì¥í•˜ëŠ” ê²½ìš°ë§Œ ê¸°ë¡

## SemanticDistance í‰ê°€ ê°€ì´ë“œ
- ì˜¤ë‹µ-ì˜¤ë‹µ ë¹„êµ ê¸ˆì§€: SemanticDistanceëŠ” ë°˜ë“œì‹œ â€˜ì •ë‹µ(ì•µì»¤) vs ì„ íƒì§€â€™ ê¸°ì¤€ìœ¼ë¡œë§Œ íŒë‹¨í•©ë‹ˆë‹¤. ì˜¤ë‹µ ê°„ ë¹„êµ ê²°ê³¼ëŠ” ê¸°ë¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ê¸°ë¡ ì¡°ê±´(ì •ë‹µ ê¸°ì¤€ ì „ìš©): ì•„ë˜ 3ì¶• ì¤‘ 2ê°œ ì´ìƒì´ â€˜ëª…í™•â€™í•˜ê²Œ ìƒì´/ìƒë°˜ì¼ ë•Œì—ë§Œ SemanticDistanceë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
  - ë²•ë¦¬ ë²”ì£¼ ìƒì´(ì˜ˆ: ì¦ê±°ëŠ¥ë ¥ vs ì¦ëª…ë ¥)
  - í•µì‹¬ ìš”ê±´/ì „ì œ ìƒì´(ì˜ˆ: ë°˜ëŒ€ì‹ ë¬¸ê¶Œ ë³´ì¥ ì—¬ë¶€, êµ¬ì„±ìš”ê±´ ì¶©ì¡±ìš”ì†Œ)
  - ê²°ë¡ Â·íš¨ê³¼ ìƒë°˜(ì˜ˆ: í—ˆìš© vs ê¸ˆì§€, ì¸ì • vs ë¶ˆì¸ì •)
- ë¹„ê¸°ë¡ ì›ì¹™: ë™ì¼ ë²•ë¦¬ ë‚´ ê²½ë¯¸í•œ ì„œìˆ Â·ìˆ˜ì‹Â·ì˜ˆì™¸ì¡°ê±´ ì°¨ì´ëŠ” ê¸°ë¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 2ê°œ ë¯¸ë§Œ ì¶©ì¡± ì‹œ SemanticDistance ë¯¸ê¸°ë¡(í•„ìš”í•˜ë©´ LogicalGapë¡œë§Œ ê¸°ë¡).
- ì½”ë©˜íŠ¸ ìš”ê±´(ì™„í™”): ì„ íƒì§€ ë²ˆí˜¸ë§Œ ëª…ì‹œí•˜ê³ , ì°¨ì´ì˜ â€˜ì¶•(ë²•ë¦¬/ì „ì œ/ê²°ë¡ )â€™ì„ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ì§ì ‘ ì¸ìš©ì€ ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤.
- ê²½ê³„ì„  ì²˜ë¦¬: ê²½ê³„ì„  ì‚¬ë¡€ëŠ” SemanticDistanceë¡œ ê¸°ë¡í•˜ì§€ ë§ê³ , ê·¼ê±° ë¶€ì¡± ë¬¸ì œëŠ” LogicalGapìœ¼ë¡œë§Œ ê²€í† í•˜ê±°ë‚˜ ë¯¸ê¸°ë¡í•©ë‹ˆë‹¤.

ì¤‘ìš” ì§€ì¹¨:
- ì—ëŸ¬ëŠ” í™•ì‹¤íˆ ë‹¨ì •í•  ìˆ˜ ìˆëŠ” ê²½ìš°ì—ë§Œ ê¸°ë¡í•˜ì„¸ìš”. "ê°™ìŒ/ë³´ì„/ì¶”ì •/ê°€ëŠ¥ì„±/ì˜ì‹¬" ë“± ì¶”ì • í‘œí˜„ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.
- errors ë°°ì—´ì—ëŠ” ì‹¤ì œë¡œ í•´ë‹¹ë˜ëŠ” ìœ í˜•ë§Œ í¬í•¨í•˜ì„¸ìš”. í•´ë‹¹ë˜ì§€ ì•Šìœ¼ë©´ ê·¸ ìœ í˜•ì˜ í•­ëª© ìì²´ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”.
- ê° ì—ëŸ¬ ê°ì²´ì˜ "comment" í‚¤ëŠ” êµ¬ì²´ì ì´ê³  í™•ì •ì ì¸ ê·¼ê±°ê°€ ìˆì„ ë•Œë§Œ ì“°ì„¸ìš”. "ê·¼ê±° ë¶€ì¡±", "ê±°ë¦¬ ê³¼ë„"ì™€ ê°™ì€ í¬ê´„ í‘œí˜„ë§Œ ìˆëŠ” ì½”ë©˜íŠ¸ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤. ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ (type,comment) ìŒ ìì²´ë¥¼ ìƒëµí•˜ì„¸ìš”.
- ê°™ì€ typeì˜ ì—ëŸ¬ëŠ” ì—¬ëŸ¬ ê°œ ìƒì„±í•˜ì§€ ë§ê³  ë°˜ë“œì‹œ 1ê°œë¡œ í†µí•©í•˜ì„¸ìš”. ì—¬ëŸ¬ ê·¼ê±°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ typeì˜ ë‹¨ì¼ ê°ì²´ì˜ commentì— ê°„ê²°íˆ ë³‘ê¸°í•˜ì„¸ìš”.

ì¢‹ì€ comment ì˜ˆì‹œ:
- LogicalGap: [ì„ íƒì§€ ã„´] [ì¸ìš©] "ì¦ê±°ëŠ¥ë ¥ì´ ì—†ë‹¤" â†’ [ì—°ì‡„ëˆ„ë½] (ìë°±ë³´ê°• í•„ìš”ì„±)â†’(í˜•ì†Œë²• ì œ312ì¡° ì œ4í•­ ìš”ê±´ ì¶©ì¡± ì—¬ë¶€) ì¤‘ í›„ë‹¨ ëˆ„ë½; [ìš”êµ¬ ê·¼ê±°] í˜•ì†Œë²• ì œ312ì¡° ì œ4í•­, ëŒ€ë²•ì› 2015ë„12345(2016.3.24.); [ë¶€ì¡± ì´ìœ ] ë°˜ëŒ€ì‹ ë¬¸ê¶Œ ë³´ì¥Â·íŠ¹ì‹ ìƒíƒœ ìš”ê±´ í‰ê°€ ë¶€ì¬; [ê°œì„ ] "ë°˜ëŒ€ì‹ ë¬¸ê¶Œ ë³´ì¥ ë° íŠ¹ì‹ ìƒíƒœ ì¸ì • ì‹œì— í•œí•´ ì¦ê±°ëŠ¥ë ¥ ë¶€ì •ì´ ì•„ë‹ˆë¼ ì œí•œì ìœ¼ë¡œ ì¸ì •ë¨"ìœ¼ë¡œ ìˆ˜ì •.
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ë¥˜ê°€ ì—†ë‹¤ë©´ errorsëŠ” ë¹ˆ ë°°ì—´([])ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

{{
  "validity": "High/Medium/Low",
  "errors": [
    {{"type": "SemanticDistance", "comment": "ì •ë‹µ-ì˜¤ë‹µ ê°„ ì˜ë¯¸ì  ê±°ë¦¬ë¥¼ ë‹¨ì •ì ìœ¼ë¡œ ê¸°ì¬"}},
    {{"type": "Hallucination", "comment": "êµ¬ì²´ì ì¸ í™˜ê° ë‚´ìš© ê¸°ì¬"}}
    {{"type": "StructuralIssue", "comment": "í•µì‹¬ êµ¬ì¡° ê²°í•¨ì„ ë‹¨ì •ì ìœ¼ë¡œ ê¸°ì¬"}},
    {{"type": "Overlap", "comment": "ì„ íƒì§€ ê°„ ì˜ë¯¸ì  ì¤‘ë³µì„ ë‹¨ì •ì ìœ¼ë¡œ ê¸°ì¬"}},
    {{"type": "LogicalGap", "comment": "ì§€ë¬¸ ë‚´ ê·¼ê±° ë¶€ì¬ë¥¼ ë‹¨ì •ì ìœ¼ë¡œ ê¸°ì¬"}}
  ],
  "recommendation": "Keep",
  "detailed_analysis": {{
    "distractor_quality": "ì˜¤ë‹µì„ ì§€ í’ˆì§ˆ ìƒì„¸ ë¶„ì„",
    "structural_coherence": "êµ¬ì¡°ì  ì¼ê´€ì„± ìƒì„¸ ë¶„ì„",
    "semantic_distance": "ì˜ë¯¸ì  ê±°ë¦¬ ë¶„ì„",
    "overall_assessment": "ì¢…í•© í‰ê°€"
  }}
}}
"""

def judge_question(row):
    question = row.get("question") or row.get("\ufeffquestion") or ""
    answers = [
        row.get("answer1", ""),
        row.get("answer2", ""),
        row.get("answer3", ""),
        row.get("answer4", ""),
        row.get("answer5", "")
    ]
    solution = row.get("solution", "") or row.get("\ufeffsolution", "")
    prompt = llm_judge_prompt(question, answers, solution)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
    )
    
    try:
        result_text = response.choices[0].message.content.strip()
        
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json``` ë¸”ë¡ì´ë‚˜ ìˆœìˆ˜ JSON)
        if "```json" in result_text:
            start = result_text.find("```json") + 7
            end = result_text.find("```", start)
            if end != -1:
                result_text = result_text[start:end].strip()
        elif "```" in result_text:
            start = result_text.find("```") + 3
            end = result_text.find("```", start)
            if end != -1:
                result_text = result_text[start:end].strip()
        
        # JSON ì‹œì‘ê³¼ ë ì°¾ê¸°
        if result_text.startswith("{"):
            # {ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°, ë§ˆì§€ë§‰ } ì°¾ê¸°
            brace_count = 0
            for i, char in enumerate(result_text):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        result_text = result_text[:i+1]
                        break
        
        result = json.loads(result_text)

        # ì¤‘ë³µ type ë°©ì§€: ê°™ì€ typeì€ 1ê°œë¡œ í†µí•©
        try:
            errors = result.get("errors", [])
            if isinstance(errors, list):
                merged_by_type = {}
                for err in errors:
                    if not isinstance(err, dict):
                        continue
                    err_type = (err.get("type") or "").strip()
                    if not err_type:
                        continue
                    # ë¹ˆ ì½”ë©˜íŠ¸ëŠ” ìƒëµ ê·œì¹™ ìœ ì§€
                    err_comment = (err.get("comment") or "").strip()
                    if err_type not in merged_by_type:
                        merged_by_type[err_type] = {"type": err_type}
                        if err_comment:
                            merged_by_type[err_type]["comment"] = err_comment
                    else:
                        # ê¸°ì¡´ commentì™€ ë³‘í•©(ì¤‘ë³µ ë¬¸êµ¬ ì œê±°)
                        prev = merged_by_type[err_type]
                        comments = []
                        if isinstance(prev.get("comment"), str) and prev["comment"].strip():
                            comments.append(prev["comment"].strip())
                        if err_comment:
                            comments.append(err_comment)
                        # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°
                        seen = set()
                        merged_texts = []
                        for c in comments:
                            if c not in seen:
                                seen.add(c)
                                merged_texts.append(c)
                        if merged_texts:
                            prev["comment"] = "; ".join(merged_texts)
                        else:
                            prev.pop("comment", None)
                result["errors"] = list(merged_by_type.values())
        except Exception as _:
            # ë¬¸ì œê°€ ìˆì–´ë„ íŒŒì‹± ìì²´ëŠ” ìœ ì§€
            pass

        # Hallucination ì—„ê²© ê²€ì¦: ëª¨í˜¸í•˜ê±°ë‚˜ ê·¼ê±° ë¶ˆì¶©ë¶„í•˜ë©´ SemanticDistanceë¡œ ê°•ë“±
        try:
            def _is_ambiguous(text: str) -> bool:
                if not text:
                    return True
                compact = text.replace(" ", "")
                ambiguous_markers = [
                    "ê°™ìŒ", "ë³´ì„", "ë“¯", "ì¶”ì •", "ê°€ëŠ¥", "ê°€ëŠ¥ì„±", "í• ìˆ˜", "í•  ìˆ˜", "ë³¼ìˆ˜ìˆ", "ë³¼ ìˆ˜ ìˆ", "í•´ì„ì—ë”°ë¼", "í•´ì„ì— ë”°ë¼",
                    "~ë¡œë³¼ìˆ˜", "~ë¡œ ë³¼ ìˆ˜", "ì˜ê²¬", "ì¶”ì¸¡"
                ]
                return any(m in compact for m in ambiguous_markers)

            def _hallucination_has_required_evidence(text: str) -> bool:
                if not text:
                    return False
                if _is_ambiguous(text):
                    return False
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°ë¬¸/ìš©ì–´ ì°½ì‘ ì£¼ì¥ + ê·¼ì ‘ íŒ¨í„´
                has_article_pattern = bool(re.search(r"ì œ\s*\d+\s*ì¡°", text))
                claims_nonexist = any(k in text for k in ["ì¡´ì¬í•˜ì§€ ì•Š", "ì‹¤ì¬í•˜ì§€ ì•Š", "ì—†ëŠ” ì¡°ë¬¸", "í—ˆêµ¬", "ì°½ì‘", "ë‚ ì¡°"])
                has_nonexistent_claim = has_article_pattern and claims_nonexist

                # íŒë¡€/ì¡°ë¬¸ ì›ë¬¸ ì¸ìš© + ì •ë©´ ëª¨ìˆœ ë‹¨ì •
                has_case_anchor = any(k in text for k in ["ëŒ€ë²•ì›", "í—Œë²•ì¬íŒì†Œ", "ì„ ê³ ", "ì‚¬ê±´ë²ˆí˜¸", "ì „ì›í•©ì˜ì²´", "ê³ ë“±ë²•ì›"]) or bool(re.search(r"\d{4}\s*\w+\s*\d+", text))
                has_contradiction = any(k in text for k in ["ì •ë©´ìœ¼ë¡œ", "ëª¨ìˆœ", "ë°˜í•¨", "ë°°ì¹˜", "ì •ë°˜ëŒ€"])
                has_direct_citation_contradiction = has_case_anchor and has_contradiction

                # ë‹¨ì •ì  ì–´ì¡°(ëª¨í˜¸ ê¸ˆì§€) í™•ì¸
                has_assertive_tone = any(k in text for k in ["ì´ë‹¤", "ì„", "ì•„ë‹ˆë‹¤", "ì•„ë‹˜", "ë‹¨ì •", "ëª…ë°±", "í™•ì •"])

                return has_assertive_tone and (has_nonexistent_claim or has_direct_citation_contradiction)

            errs = result.get("errors", [])
            if isinstance(errs, list):
                refined = []
                for e in errs:
                    if not isinstance(e, dict):
                        continue
                    e_type = (e.get("type") or "").strip()
                    comment = (e.get("comment") or "").strip()
                    if e_type == "Hallucination":
                        if not _hallucination_has_required_evidence(comment):
                            # ê·¼ê±°ê°€ ì•½í•˜ë©´ í™˜ê°ìœ¼ë¡œ ê¸°ë¡í•˜ì§€ ì•Šê³  SemanticDistanceë¡œ ì¬ë¶„ë¥˜
                            if comment:
                                refined.append({"type": "SemanticDistance", "comment": comment})
                            # ì½”ë©˜íŠ¸ê°€ ì—†ìœ¼ë©´ ì•„ì˜ˆ ìƒëµ
                            continue
                    refined.append(e)
                result["errors"] = refined
                # ê°•ë“± í›„ ë™ì¼ type ì¤‘ë³µ ì œê±° ë° comment ë³‘í•©
                try:
                    merged_by_type = {}
                    for err in result.get("errors", []) or []:
                        if not isinstance(err, dict):
                            continue
                        t = (err.get("type") or "").strip()
                        if not t:
                            continue
                        c = (err.get("comment") or "").strip()
                        if t not in merged_by_type:
                            merged_by_type[t] = {"type": t}
                            if c:
                                merged_by_type[t]["comment"] = c
                        else:
                            if c:
                                prev_c = merged_by_type[t].get("comment", "").strip()
                                if prev_c and c and c not in prev_c:
                                    merged_by_type[t]["comment"] = f"{prev_c}; {c}" if prev_c else c
                                elif not prev_c and c:
                                    merged_by_type[t]["comment"] = c
                    result["errors"] = list(merged_by_type.values())
                except Exception:
                    pass
        except Exception:
            pass
    except Exception as e:
        print("âš ï¸ JSON Parse Error:", e)
        print(f"ğŸ” ì „ì²´ ì‘ë‹µ: {result_text}")
        return None
    return result

# Update scoring logic to reflect scores for all but ambiguous cases

def _compute_weighted_score(errors):
    score = 0.0
    for e in errors or []:
        if not e:
            continue
        e_type = (e.get("type") or "").strip()
        raw_comment = e.get("comment")
        # ì½”ë©˜íŠ¸ê°€ ì—†ìœ¼ë©´ ì ìˆ˜í™”í•˜ì§€ ì•ŠìŒ
        if not raw_comment:
            continue
        comment = raw_comment.strip().lower()

        # í™•ì • ë° ë¹„í™•ì • í¬í•¨, ì• ë§¤í•œ ì–´ì¡°ëŠ” ì œì™¸
        compact = comment.replace(" ", "")
        is_ambiguous = any(k in compact for k in ["ìˆ˜ìˆìŒ", "ìˆ˜ìˆë‹¤", "ìˆ˜ ìˆì„", "ë³´ì…ë‹ˆë‹¤", "ì—†ìŒ", "ìˆìŒ", "ê°€ëŠ¥ì„±"])

        # ì ìˆ˜ëŠ” ì• ë§¤í•˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ë°˜ì˜
        if is_ambiguous:
            continue

        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ë°˜ì˜
        if e_type == "Hallucination":
            score += 20
        # elif e_type == "DistractorIssue":
        #     score += 4  # ì£¼ì„ ì²˜ë¦¬: ì˜¤ë¥˜ íƒì§€(ë²•ë¦¬ ë°©í–¥ì„±) ì ìˆ˜ ë°˜ì˜ ë¹„í™œì„±í™”
        elif e_type == "StructuralIssue":
            score += 5
        elif e_type == "SemanticDistance":
            score += 5
        elif e_type == "LogicalGap":
            score += 3
        elif e_type == "Overlap":
            score += 3

        # ì‹¬ê°ë„ í‚¤ì›Œë“œ ë³´ì •
        if any(k in comment for k in ["ì¹˜ëª…", "ì „í˜€", "ì™„ì „íˆ", "ë¶ˆê°€ëŠ¥", "ëª…ë°±", "ê·¹ë‹¨"]):
            score += 3
        elif any(k in comment for k in ["ì‹¬ê°", "í¬ë‹¤", "ê³¼ë„", "í˜„ì €"]):
            score += 2
        elif any(k in comment for k in ["ë¶€ë¶„ì ", "ê²½ë¯¸", "ì¼ë¶€"]):
            score += 1

        # íŠ¹ì • í•­ëª© ê°€ì¤‘ì¹˜ ê°•í™”
        # if e_type == "DistractorIssue" and any(k in comment for k in ["ëª…ë°±í•œ ë¶€ì •í˜•", "ë¶€ì •í˜• ì§„ìˆ "]):
        #     score += 5  # ì£¼ì„ ì²˜ë¦¬: DistractorIssue ê°€ì¤‘ì¹˜ ë¹„í™œì„±í™”
        if e_type == "SemanticDistance" and any(k in comment for k in ["ì™„ì „íˆ ë¶ˆì¼ì¹˜", "ì „í˜€ ê´€ë ¨ì—†ìŒ", "ì™„ì „íˆ ë‹¤ë¦„"]):
            score += 5
        if e_type == "LogicalGap" and any(k in comment for k in ["ë…¼ë¦¬ì  ê·¼ê±° ì—†ì´", "ë‹¨ë…ìœ¼ë¡œ ë“±ì¥", "ê·¼ê±° ë¶€ì¡±"]):
            score += 4

        # í™•ì • ì–´ì¡° ë³´ë„ˆìŠ¤
        score += 2
    return score

# Updated passes_filter logic
THRESHOLD_HARD_BLOCK = 15.0  # í™˜ê°ê³¼ ì‹¬ê°í•œ ì˜¤ë¥˜ì— ëŒ€í•œ ì¦‰ì‹œ ì°¨ë‹¨ ì„ê³„ê°’

def passes_filter(result, filter_reasons=None):
    try:
        if not result:
            return True

        validity = result.get("validity", "")
        recommendation = result.get("recommendation", "")
        errors = result.get("errors", [])
        
        # errorsê°€ Noneì´ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if not isinstance(errors, list):
            errors = []

        #0. ê¸°ë³¸ ì´ˆê¸°í™”
        if filter_reasons is None:
            filter_reasons = {}

        # 0-1. ê³µì‹ ê¸°ì¶œ ë³´í˜¸ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¡°ê¸° íŒì •
        # errors ì •ê·œí™”
        try:
            errors = result.get("errors", [])
            if not isinstance(errors, list):
                errors = []
        except Exception:
            errors = []

        # ëª…ë°±í•œ í™˜ê°ì€ ì¦‰ì‹œ ì°¨ë‹¨
        for e in errors:
            if e and e.get("type") == "Hallucination":
                comment = (e.get("comment") or "").lower()
                if any(k in comment for k in ["ì¡´ì¬í•˜ì§€ ì•ŠëŠ”", "í—ˆêµ¬", "ë‚ ì¡°", "ì™„ì „íˆ ì˜ëª»ëœ"]):
                    if filter_reasons is not None:
                        filter_reasons["hallucination"] = filter_reasons.get("hallucination", 0) + 1
                    return False

        total_score = _compute_weighted_score(errors)
        if total_score >= THRESHOLD_HARD_BLOCK:
            if filter_reasons is not None:
                filter_reasons["hard_block"] = filter_reasons.get("hard_block", 0) + 1
            return False
        if 6.0 <= total_score < THRESHOLD_HARD_BLOCK and filter_reasons is not None:
            filter_reasons["warn"] = filter_reasons.get("warn", [])
            filter_reasons["warn"].append("manual review recommended")
        # ì¡°ê¸° í†µê³¼
        return True

    except Exception as ex:
        print(f"âš ï¸ í•„í„°ë§ í•¨ìˆ˜ ì˜¤ë¥˜: {ex}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ í†µê³¼ ì²˜ë¦¬
        return True

def filter_mcqa(input_csv, output_csv, start_line=1):
    with open(input_csv, newline='', encoding='utf-8-sig') as infile, \
         open(output_csv, "a", newline='', encoding='utf-8') as outfile:

        reader = csv.DictReader(infile)
        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)
        
        # íŒŒì¼ì´ ë¹„ì–´ìˆì„ ë•Œë§Œ í—¤ë” ì“°ê¸°
        outfile.seek(0, 2)  # íŒŒì¼ ëìœ¼ë¡œ ì´ë™
        if outfile.tell() == 0:  # íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´
            writer.writeheader()

        # ì „ì²´ í–‰ ìˆ˜ ê³„ì‚°
        rows = list(reader)
        total_rows = len(rows)
        
        # ì‹œì‘ ë¼ì¸ ì²˜ë¦¬
        if start_line > 1:
            rows = rows[start_line-1:]  # start_line-1 ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘ (0-based)
            print(f"ğŸ“ {start_line}ë²ˆì§¸ ë¼ì¸ë¶€í„° ì²˜ë¦¬ ì‹œì‘ (ì´ {len(rows)}ê°œ ë¬¸í•­)")
        
        passed_count = 0
        filtered_count = 0
        filter_reasons = {
            "validity_low": 0,
            "recommendation_remove": 0,
            "difficulty_extreme": 0,
            "hallucination": 0,
            "distractor_issues": 0,
            "structural_issues": 0,
            "semantic_distance": 0,
            "logical_gap": 0,
            "answer_validity": 0,
            "overlap": 0,
            "obvious_negative": 0,
            "factual_only": 0,
            "insufficient_grounds": 0,
            "excessive_distance": 0,
            "hard_block": 0
        }
        
        # ì ìˆ˜ í‰ê·  ì§‘ê³„ë¥¼ ìœ„í•œ ëˆ„ì  ë³€ìˆ˜
        sum_total_score = 0.0
        num_total_scored = 0
        sum_passed_score = 0.0
        num_passed_scored = 0
        sum_filtered_score = 0.0
        num_filtered_scored = 0

        # ì ìˆ˜ ë°°ì—´ ìˆ˜ì§‘ (ìš”ì²­: ë°°ì—´ í˜•íƒœë¡œ ì¶œë ¥/ì €ì¥)
        all_scores = []
        passed_scores = []
        filtered_scores = []
        
        # tqdmìœ¼ë¡œ ì§„í–‰ë„ í‘œì‹œ
        if not filter_reasons:
            filter_reasons = {}

        # í•„í„°ë§ ì‚¬ìœ ë¥¼ outputì— ì €ì¥í•˜ëŠ” ë¶€ë¶„ ì¶”ê°€
        filtered_output = []

        # Ensure output.json starts with a valid JSON structure if it's empty or invalid
        if not os.path.exists('output.json') or os.stat('output.json').st_size == 0:
            with open('output.json', 'w', encoding='utf-8') as json_file:
                json.dump([], json_file, ensure_ascii=False, indent=4)
        else:
            # Validate JSON structure
            with open('output.json', 'r+', encoding='utf-8') as json_file:
                try:
                    json.load(json_file)
                except json.JSONDecodeError:
                    json_file.seek(0)
                    json_file.truncate()
                    json.dump([], json_file, ensure_ascii=False, indent=4)

        # Ensure score.json starts with a valid JSON structure if it's empty or invalid
        score_json_path = 'score.json'
        if not os.path.exists(score_json_path) or os.stat(score_json_path).st_size == 0:
            # append ëª¨ë“œë¡œë„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±ë˜ë©°, ì´ˆê¸° êµ¬ì¡°ë¥¼ ê¸°ë¡
            with open(score_json_path, 'a', encoding='utf-8') as json_file:
                json.dump({"all": [], "passed": [], "filtered": []}, json_file, ensure_ascii=False, indent=4)
        else:
            # Validate JSON structure
            with open(score_json_path, 'r+', encoding='utf-8') as json_file:
                try:
                    json.load(json_file)
                except json.JSONDecodeError:
                    json_file.seek(0)
                    json_file.truncate()
                    json.dump({"all": [], "passed": [], "filtered": []}, json_file, ensure_ascii=False, indent=4)

        for i, row in enumerate(tqdm(rows, desc="ë¬¸í•­ í‰ê°€ ì¤‘", unit="ë¬¸í•­"), start=start_line):
            try:
                q_preview = (row.get('question') or row.get('\ufeffquestion') or '')
                tqdm.write(f"ğŸ” Evaluating Q{i}: {q_preview[:40]}...")
                result = judge_question(row)

                # ì ìˆ˜ ê³„ì‚° (ë¡œê¹…ìš©)
                try:
                    score_for_log = _compute_weighted_score(result.get("errors", [])) if result else 0.0
                except Exception:
                    score_for_log = 0.0
                
                # ì „ì²´ í‰ê·  ì§‘ê³„
                sum_total_score += score_for_log
                num_total_scored += 1
                # ì „ì²´ ë°°ì—´ ìˆ˜ì§‘
                all_scores.append(score_for_log)

                if passes_filter(result, filter_reasons):
                    writer.writerow(row)
                    passed_count += 1
                    tqdm.write(f" PASSED â†’ Outputì— ì¶”ê°€ë¨")
                    tqdm.write(f"   ğŸ§® ì ìˆ˜: {score_for_log}")
                    # í†µê³¼ í‰ê·  ì§‘ê³„
                    sum_passed_score += score_for_log
                    num_passed_scored += 1
                    # í†µê³¼ ë°°ì—´ ìˆ˜ì§‘
                    passed_scores.append(score_for_log)
                    if result and result.get("detailed_analysis"):
                        analysis = result["detailed_analysis"]
                        tqdm.write(f"   ğŸ“ ì¢…í•©í‰ê°€: {analysis.get('overall_assessment', 'N/A')[:50]}...")
                else:
                    filtered_count += 1
                    tqdm.write(f" FILTERED OUT")
                    tqdm.write(f"   ğŸ§® ì ìˆ˜: {score_for_log}")
                    # í•„í„° í‰ê·  ì§‘ê³„
                    sum_filtered_score += score_for_log
                    num_filtered_scored += 1
                    # í•„í„° ë°°ì—´ ìˆ˜ì§‘
                    filtered_scores.append(score_for_log)
                    if result:
                        errors = result.get("errors", [])
                        if errors:
                            tqdm.write(f"    í•„í„°ë§ ì‚¬ìœ :")
                            for error in errors[:3]:  # ìµœëŒ€ 3ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
                                tqdm.write(f"      - {error.get('type', 'Unknown')}: {error.get('comment', '')[:60]}...")
                        if result.get("recommendation") == "Remove":
                            tqdm.write(f"    ê¶Œì¥ì‚¬í•­: ì œê±°")
                        elif result.get("validity") == "Low":
                            tqdm.write(f"    íƒ€ë‹¹ì„±: ë‚®ìŒ")

                    # output.jsonì— í•„í„°ë§ ì‚¬ìœ  ì €ì¥
                    filtered_output.append({
                        'question_index': i,
                        'question_preview': q_preview,
                        'errors': errors,
                        'score': score_for_log
                    })
            except Exception as ex:
                print(f"âš ï¸ ë¬¸í•­ {i} ì²˜ë¦¬ ì˜¤ë¥˜: {ex}")
                writer.writerow(row)
                passed_count += 1
                tqdm.write(f" ERROR â†’ ì•ˆì „í•˜ê²Œ í†µê³¼ ì²˜ë¦¬ë¨")

        # í•„í„°ë§ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        # Append data to output.json
        if os.path.exists('output.json'):
            with open('output.json', 'r+', encoding='utf-8') as json_file:
                existing_data = json.load(json_file)
                json_file.seek(0)
                json_file.truncate()
                json.dump(existing_data + filtered_output, json_file, ensure_ascii=False, indent=4)
        else:
            with open('output.json', 'w', encoding='utf-8') as json_file:
                json.dump(filtered_output, json_file, ensure_ascii=False, indent=4)

    print(f"\n í•„í„°ë§ ì™„ë£Œ!")
    print(f"    ì´ ë¬¸í•­: {total_rows}ê°œ")
    print(f"    í†µê³¼: {passed_count}ê°œ")
    print(f"    í•„í„°ë§: {filtered_count}ê°œ")
    print(f"    ê²°ê³¼ íŒŒì¼: '{output_csv}'")
    
    # í‰ê·  ì ìˆ˜ ì¶œë ¥
    try:
        if num_total_scored > 0:
            overall_avg = sum_total_score / max(1, num_total_scored)
            print(f"\n    í‰ê·  ì ìˆ˜(ì „ì²´): {overall_avg:.2f} (N={num_total_scored})")
        if num_passed_scored > 0:
            passed_avg = sum_passed_score / max(1, num_passed_scored)
            print(f"    í‰ê·  ì ìˆ˜(í†µê³¼): {passed_avg:.2f} (N={num_passed_scored})")
        if num_filtered_scored > 0:
            filtered_avg = sum_filtered_score / max(1, num_filtered_scored)
            print(f"    í‰ê·  ì ìˆ˜(í•„í„°ë§): {filtered_avg:.2f} (N={num_filtered_scored})")
    except Exception as _:
        pass

    # ì ìˆ˜ ë°°ì—´ ì¶œë ¥
    try:
        print("\n    ì ìˆ˜ ë°°ì—´(ì „ì²´):", json.dumps(all_scores, ensure_ascii=False))
        print("    ì ìˆ˜ ë°°ì—´(í†µê³¼):", json.dumps(passed_scores, ensure_ascii=False))
        print("    ì ìˆ˜ ë°°ì—´(í•„í„°ë§):", json.dumps(filtered_scores, ensure_ascii=False))
    except Exception as _:
        pass

    # score.jsonì— ëˆ„ì  ì €ì¥ (ì¤‘ë‹¨ ëŒ€ë¹„: ê¸°ì¡´ ë°°ì—´ì— ì´ì–´ë¶™ì´ê¸°)
    try:
        score_payload = {
            "all": all_scores,
            "passed": passed_scores,
            "filtered": filtered_scores,
        }
        if os.path.exists('score.json'):
            with open('score.json', 'r+', encoding='utf-8') as f:
                try:
                    existing = json.load(f)
                except Exception:
                    existing = {}
                if not isinstance(existing, dict):
                    existing = {}
                existing.setdefault('all', [])
                existing.setdefault('passed', [])
                existing.setdefault('filtered', [])
                # ì´ì–´ë¶™ì´ê¸°
                existing['all'].extend(score_payload['all'])
                existing['passed'].extend(score_payload['passed'])
                existing['filtered'].extend(score_payload['filtered'])
                f.seek(0)
                f.truncate()
                json.dump(existing, f, ensure_ascii=False, indent=4)
        else:
            with open('score.json', 'w', encoding='utf-8') as f:
                json.dump(score_payload, f, ensure_ascii=False, indent=4)
    except Exception as _:
        pass


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë²•ë¥  MCQA ë°ì´í„°ì…‹ í•„í„°ë§")
    parser.add_argument("--name", type=str, required=True, help="íŒŒì¼ ì´ë¦„")
    parser.add_argument("--start-line", type=int, default=1, help="ì‹œì‘ ë¼ì¸ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)")
    args = parser.parse_args()
    
    name = args.name
    start_line = args.start_line
    input_file = f"{name}.csv"
    output_file = f"{name}_filtered.csv"
    
    print(f" ì…ë ¥ íŒŒì¼: {input_file}")
    print(f" ì¶œë ¥ íŒŒì¼: {output_file}")
    print(f" ì‹œì‘ ë¼ì¸: {start_line}")
    
    filter_mcqa(input_file, output_file, start_line)
