import csv, json, openai
import os
import argparse
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def llm_judge_prompt(context, question, answers):
    return f"""
ë‹¹ì‹ ì€ 'ë²•ë¥  MCQA ë°ì´í„°ì…‹ ê²€ì¦ ì „ë¬¸ê°€(Legal MCQA Evaluator)'ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸í•­ì˜ í’ˆì§ˆì„ ë²•ë¦¬ì Â·ë…¼ë¦¬ì ìœ¼ë¡œ ì¢…í•© í‰ê°€í•˜ì„¸ìš”.

### [ì§€ë¬¸]
{context}

### [ì§ˆë¬¸]
{question}

### [ì„ íƒì§€]
1. {answers[0]}
2. {answers[1]}
3. {answers[2]}
4. {answers[3]}
5. {answers[4]}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œë§Œ í‰ê°€ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì‹­ì‹œì˜¤:

## 2. ì˜¤ë‹µì„ ì§€ì˜ ë²•ë¦¬ì  íƒ€ë‹¹ì„±ê³¼ ì˜¤ë¥˜ ë°©í–¥ì„± (Distractor Quality) - ì™„í™”
- ì˜¤ë‹µì´ ì™„ì „íˆ ë¬´ì˜ë¯¸í•˜ì§€ ì•Šì€ê°€? (ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì²´í¬)

## 3. ì„ íƒì§€ ê°„ ì˜ë¯¸ì  ì¤‘ë³µ ì—¬ë¶€ (Semantic Redundancy) - ì™„í™”
- ì„ íƒì§€ê°€ ì™„ì „íˆ ë™ì¼í•˜ì§€ ì•Šì€ê°€? (ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì²´í¬)

## 4. í™˜ê° ë°œìƒ ì—¬ë¶€ (Hallucination Detection) - ì™„í™”
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë²•ë¦¬Â·íŒë¡€Â·ë²•ì¡°ë¬¸ì„ ë‹¨ì •ì ìœ¼ë¡œ ì„œìˆ í–ˆëŠ”ê°€? (ëª…ë°±í•œ í™˜ê°ë§Œ ì²´í¬)

## 5. ë¬¸í•­ êµ¬ì¡° ë° ì¼ê´€ì„± (Structural Coherence) - ì™„í™”
- ë¬¸í•­ì´ ì™„ì „íˆ ì´í•´ ë¶ˆê°€ëŠ¥í•˜ì§€ ì•Šì€ê°€? (ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì²´í¬)

## 6. ë‚œì´ë„ ì¶”ì • (Difficulty Scoring)
- 1ì : ë‹¨ìˆœ ì•”ê¸°í˜•
- 2ì : ë‹¨ì¼ ë²•ë¦¬ ì ìš©í˜•
- 3ì : ì‚¬ì‹¤ê³¼ ë²•ë¦¬ ê²°í•©í˜•
- 4ì : ì˜ˆì™¸Â·ê²½ê³„ íŒë‹¨í˜•
- 5ì : ê³ ê¸‰ ì‘ìš©í˜•

## 7. ì¶”ê°€ ê²€ì¦ í•­ëª© (Additional Validation) - ì™„í™”
- ì •ë‹µì´ ì™„ì „íˆ ë…¼ë¦¬ì  ê·¼ê±° ì—†ì´ ë“±ì¥í•˜ì§€ëŠ” ì•ŠëŠ”ê°€? (ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì²´í¬)
- ì˜¤ë‹µì´ â€˜ë„ˆë¬´ ëª…ë°±í•œ ë¶€ì •í˜• ì§„ìˆ â€™ë¡œ ë˜ì–´ ìˆì§€ ì•Šì€ê°€?
- ì§€ë¬¸ì´ ë‹¨ìˆœ ì‚¬ì‹¤ì„œìˆ ì— ê·¸ì¹˜ì§€ ì•Šê³  ë²•ì  ìŸì ì„ ì¶©ë¶„íˆ ìœ ë„í•˜ëŠ”ê°€?
- ì •ë‹µê³¼ ì˜¤ë‹µ ê°„ ì˜ë¯¸ì  ê±°ë¦¬(semantic distance)ê°€ ì§€ë‚˜ì¹˜ê²Œ í¬ì§€ ì•Šì€ê°€?
- ì •ë‹µì´ ì§€ë¬¸ ë‚´ì—ì„œ ë…¼ë¦¬ì  ê·¼ê±° ì—†ì´ ë‹¨ë…ìœ¼ë¡œ ë“±ì¥í•˜ì§€ëŠ” ì•ŠëŠ”ê°€?

**ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

{{
  "validity": "High/Medium/Low",
  "errors": [
    {{"type": "DistractorIssue", "comment": "ì˜¤ë‹µì„ ì§€ì˜ ë²•ë¦¬ì  ë¬¸ì œì "}},
    {{"type": "Overlap", "comment": "ì„ íƒì§€ ê°„ ì˜ë¯¸ì  ì¤‘ë³µ"}},
    {{"type": "Hallucination", "comment": "í™˜ê° ë°œìƒ ë‚´ìš©"}},
    {{"type": "StructuralIssue", "comment": "êµ¬ì¡°ì  ì¼ê´€ì„± ë¬¸ì œ"}},
    {{"type": "SemanticDistance", "comment": "ì •ë‹µ-ì˜¤ë‹µ ê°„ ì˜ë¯¸ì  ê±°ë¦¬ ë¬¸ì œ"}},
    {{"type": "LogicalGap", "comment": "ë…¼ë¦¬ì  ê·¼ê±° ë¶€ì¡±"}}
  ],
  "difficulty_score": 1,
  "recommendation": "Keep",
  "detailed_analysis": {{
    "distractor_quality": "ì˜¤ë‹µì„ ì§€ í’ˆì§ˆ ìƒì„¸ ë¶„ì„", 
    "structural_coherence": "êµ¬ì¡°ì  ì¼ê´€ì„± ìƒì„¸ ë¶„ì„",
    "semantic_distance": "ì˜ë¯¸ì  ê±°ë¦¬ ë¶„ì„",
    "overall_assessment": "ì¢…í•© í‰ê°€"
  }}
}}
"""

def judge_question(row):
    prompt = llm_judge_prompt(
        row["abridged_context"],
        row["question"],
        [row["answer1"], row["answer2"], row["answer3"], row["answer4"], row["answer5"]],
    )
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
    )
    
    try:
        result_text = response.choices[0].message.content.strip()
        
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json``` ë¸”ë¡ì´ë‚˜ ìˆœìˆ˜ JSON)
        if "```json" in result_text:
            start = result_text.find("```json") + 7
            end = result_text.find("```", start)
            if end != -1:
                result_text = result_text[start:end].strip()
        elif "```" in result_text:
            start = result_text.find("```") + 3
            end = result_text.find("```", start)
            if end != -1:
                result_text = result_text[start:end].strip()
        
        # JSON ì‹œì‘ê³¼ ë ì°¾ê¸°
        if result_text.startswith("{"):
            # {ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°, ë§ˆì§€ë§‰ } ì°¾ê¸°
            brace_count = 0
            for i, char in enumerate(result_text):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        result_text = result_text[:i+1]
                        break
        
        result = json.loads(result_text)
    except Exception as e:
        print("âš ï¸ JSON Parse Error:", e)
        print(f"ğŸ” ì „ì²´ ì‘ë‹µ: {result_text}")
        return None
    return result

def passes_filter(result, filter_reasons=None):
    try:
        if not result:
            return False

        validity = result.get("validity", "")
        difficulty = result.get("difficulty_score", 3)
        recommendation = result.get("recommendation", "")
        errors = result.get("errors", [])
        
        # errorsê°€ Noneì´ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        if not isinstance(errors, list):
            errors = []

        #0. ê¸°ë³¸ ì´ˆê¸°í™”
        if filter_reasons is None:
            filter_reasons = {}

        #1. Hallucination â†’ ê·¹ë‹¨ì ì¸ ê²½ìš°ë§Œ ì œê±°
        try:
            hallucination_issues = [e for e in errors if e and e.get("type") == "Hallucination"]
            for issue in hallucination_issues:
                comment = issue.get("comment", "") if issue else ""
                if comment:
                    comment = comment.lower()
                    if any(k in comment for k in ["ì™„ì „íˆ", "ì „í˜€", "ì¡´ì¬í•˜ì§€ ì•ŠëŠ”", "ì˜ëª»ëœ"]):
                        if filter_reasons: filter_reasons["hallucination"] = filter_reasons.get("hallucination", 0) + 1
                        return False
        except Exception as ex:
            print(f"âš ï¸ Hallucination ê²€ì‚¬ ì˜¤ë¥˜: {ex}")

        #1-1. ì¶”ê°€ ê²€ì¦í•­ëª©: ëª…ë°±í•œ ë¶€ì •í˜• ì§„ìˆ  ê²€ì‚¬
        try:
            for e in errors:
                if e and e.get("type") == "DistractorIssue":
                    comment = e.get("comment", "") if e else ""
                    if comment:
                        comment = comment.lower()
                        if any(k in comment for k in ["ëª…ë°±í•œ ë¶€ì •í˜•", "ë„ˆë¬´ ëª…ë°±í•œ", "ë¶€ì •í˜• ì§„ìˆ "]):
                            if filter_reasons: filter_reasons["obvious_negative"] = filter_reasons.get("obvious_negative", 0) + 1
                            return False
        except Exception as ex:
            print(f"âš ï¸ ëª…ë°±í•œ ë¶€ì •í˜• ì§„ìˆ  ê²€ì‚¬ ì˜¤ë¥˜: {ex}")

        #1-2. ì¶”ê°€ ê²€ì¦í•­ëª©: ë‹¨ìˆœ ì‚¬ì‹¤ì„œìˆ  ê²€ì‚¬
        try:
            for e in errors:
                if e and e.get("type") == "StructuralIssue":
                    comment = e.get("comment", "") if e else ""
                    if comment:
                        comment = comment.lower()
                        if any(k in comment for k in ["ë‹¨ìˆœ ì‚¬ì‹¤ì„œìˆ ", "ë²•ì  ìŸì  ë¶€ì¡±", "ìŸì  ìœ ë„ ë¶€ì¡±"]):
                            if filter_reasons: filter_reasons["factual_only"] = filter_reasons.get("factual_only", 0) + 1
                            return False
        except Exception as ex:
            print(f"âš ï¸ ë‹¨ìˆœ ì‚¬ì‹¤ì„œìˆ  ê²€ì‚¬ ì˜¤ë¥˜: {ex}")

        #2. ìœ„í—˜ ì ìˆ˜ ê¸°ë°˜ ëˆ„ì  í‰ê°€ (AnswerValidity ì œì™¸)
        risk_score = 0
        for e in errors:
            try:
                # AnswerValidityëŠ” ìœ„í—˜ ì ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸
                if e and e.get("type") == "AnswerValidity":
                    continue
                comment = e.get("comment", "") if e else ""
                if comment:
                    comment = comment.lower()
                    if "ì¹˜ëª…" in comment:
                        risk_score += 2
                    elif any(k in comment for k in ["ì „í˜€", "ì™„ì „íˆ", "ë¶ˆê°€ëŠ¥", "ì‹¬ê°"]):
                        risk_score += 1
                    elif any(k in comment for k in ["ë¶€ë¶„ì ", "ê²½ë¯¸", "ì¼ë¶€"]):
                        risk_score += 0.5
            except Exception as ex:
                print(f"âš ï¸ ìœ„í—˜ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {ex}")
                continue

        if risk_score >= 8:  # ê·¹ë„ë¡œ ì‹¬ê°í•œ ë¬¸ì œ ëˆ„ì  ì‹œë§Œ ì œê±°
            if filter_reasons: filter_reasons["risk_high"] = filter_reasons.get("risk_high", 0) + 1
            return False

        #3. DistractorIssue (ì˜¤ë‹µ í’ˆì§ˆ) â€” 4ê°œ ì´ìƒì¼ ë•Œë§Œ ì œê±°
        distractor_issues = [e for e in errors if e and e.get("type") == "DistractorIssue"]
        if len(distractor_issues) >= 4:
            severe_distractors = [d for d in distractor_issues if any(k in d.get("comment", "") for k in ["ì¹˜ëª…", "ì™„ì „íˆ", "ì „í˜€"])]
            if severe_distractors:
                if filter_reasons: filter_reasons["distractor_issues"] = filter_reasons.get("distractor_issues", 0) + 1
                return False

        #4. StructuralIssue (êµ¬ì¡° ë¬¸ì œ) â€” ê±°ì˜ í•„í„°ë§í•˜ì§€ ì•ŠìŒ
        structural_issues = [e for e in errors if e and e.get("type") == "StructuralIssue"]
        for issue in structural_issues:
            comment = issue.get("comment", "") if issue else ""
            if comment:
                comment = comment.lower()
                if any(k in comment for k in ["ì™„ì „íˆ", "ì „í˜€", "ë¶ˆê°€ëŠ¥"]):
                    if filter_reasons: filter_reasons["structural_issues"] = filter_reasons.get("structural_issues", 0) + 1
                    return False

        #5. SemanticDistance (ì„ íƒì§€ ì˜ë¯¸ ê±°ë¦¬) â€” ê±°ì˜ í•„í„°ë§í•˜ì§€ ì•ŠìŒ
        semantic_issues = [e for e in errors if e and e.get("type") == "SemanticDistance"]
        for issue in semantic_issues:
            comment = issue.get("comment", "") if issue else ""
            if comment:
                comment = comment.lower()
                if any(k in comment for k in ["ì™„ì „íˆ ë¶ˆì¼ì¹˜", "ì „í˜€ ê´€ë ¨ì—†ìŒ", "ì™„ì „íˆ ë‹¤ë¦„"]):
                    if filter_reasons: filter_reasons["semantic_distance"] = filter_reasons.get("semantic_distance", 0) + 1
                    return False

        #6. LogicalGap (ë…¼ë¦¬ì  ë¹„ì•½) â€” 4ê°œ ì´ìƒì¼ ë•Œë§Œ ì œê±°
        logical_issues = [e for e in errors if e and e.get("type") == "LogicalGap"]
        severe_logicals = [l for l in logical_issues if any(k in l.get("comment", "") for k in ["ì™„ì „", "ì „í˜€", "ë¶ˆê°€ëŠ¥"])]
        if len(severe_logicals) >= 4:
            if filter_reasons: filter_reasons["logical_gap"] = filter_reasons.get("logical_gap", 0) + 1
            return False

        #6-1. ì¶”ê°€ ê²€ì¦í•­ëª©: ì •ë‹µì˜ ë…¼ë¦¬ì  ê·¼ê±° ë¶€ì¡± ê²€ì‚¬
        try:
            for e in errors:
                if e and e.get("type") == "LogicalGap":
                    comment = e.get("comment", "") if e else ""
                    if comment:
                        comment = comment.lower()
                        if any(k in comment for k in ["ë…¼ë¦¬ì  ê·¼ê±° ì—†ì´", "ë‹¨ë…ìœ¼ë¡œ ë“±ì¥", "ê·¼ê±° ë¶€ì¡±"]):
                            if filter_reasons: filter_reasons["insufficient_grounds"] = filter_reasons.get("insufficient_grounds", 0) + 1
                            return False
        except Exception as ex:
            print(f"âš ï¸ ë…¼ë¦¬ì  ê·¼ê±° ë¶€ì¡± ê²€ì‚¬ ì˜¤ë¥˜: {ex}")

        #6-2. ì¶”ê°€ ê²€ì¦í•­ëª©: ì˜ë¯¸ì  ê±°ë¦¬ ê³¼ë„ ê²€ì‚¬
        try:
            semantic_distance_issues = [e for e in errors if e and e.get("type") == "SemanticDistance"]
            for issue in semantic_distance_issues:
                comment = issue.get("comment", "") if issue else ""
                if comment:
                    comment = comment.lower()
                    if any(k in comment for k in ["ì§€ë‚˜ì¹˜ê²Œ í¬ë‹¤", "ê³¼ë„í•œ ê±°ë¦¬", "ì˜ë¯¸ì  ê±°ë¦¬ ê³¼ë„"]):
                        if filter_reasons: filter_reasons["excessive_distance"] = filter_reasons.get("excessive_distance", 0) + 1
                        return False
        except Exception as ex:
            print(f"âš ï¸ ì˜ë¯¸ì  ê±°ë¦¬ ê³¼ë„ ê²€ì‚¬ ì˜¤ë¥˜: {ex}")

        #7. Validity + Recommendation â€” AnswerValidity ê´€ë ¨ í•„í„°ë§ ì£¼ì„ì²˜ë¦¬
        # error_count = len(errors)
        # if validity.lower() == "low" and recommendation.lower() in ["remove"] and error_count >= 5:
        #     if filter_reasons: filter_reasons["validity_low"] = filter_reasons.get("validity_low", 0) + 1
        #     return False

        #8. ë‚œì´ë„ í•„í„°ë§ ì œê±° (ëª¨ë“  ë‚œì´ë„ í—ˆìš©)
        # â†’ 1ì , 5ì  ë¬¸ì œë„ í†µê³¼ì‹œì¼œì„œ í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ íŒë‹¨

        #9. Soft Filtering ê²½ê³  (ê²½ê³„ì„  ë¬¸í•­)
        if 2.5 <= risk_score < 4:
            if filter_reasons: 
                filter_reasons["warn"] = filter_reasons.get("warn", [])
                filter_reasons["warn"].append("manual review recommended")
            # í†µê³¼ëŠ” ì‹œí‚¤ë˜ í›„ì²˜ë¦¬ ê²€í†  í•„ìš”

        #10. ì¤‘ë³µ ë¬¸ì œ ê²€ì‚¬ (5ê°œ ì´ìƒì˜ ì¤‘ë³µë§Œ í•„í„°ë§)
        overlap_count = sum(1 for e in errors if e and e.get("type") == "Overlap")
        if overlap_count >= 5:
            if filter_reasons: filter_reasons["overlap"] += 1
            return False

        #11. í†µê³¼
        return True
        
    except Exception as ex:
        print(f"âš ï¸ í•„í„°ë§ í•¨ìˆ˜ ì˜¤ë¥˜: {ex}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ í†µê³¼ ì²˜ë¦¬
        return True

def filter_mcqa(input_csv, output_csv, start_line=1):
    with open(input_csv, newline='', encoding='utf-8') as infile, \
         open(output_csv, "a", newline='', encoding='utf-8') as outfile:

        reader = csv.DictReader(infile)
        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)
        
        # íŒŒì¼ì´ ë¹„ì–´ìˆì„ ë•Œë§Œ í—¤ë” ì“°ê¸°
        outfile.seek(0, 2)  # íŒŒì¼ ëìœ¼ë¡œ ì´ë™
        if outfile.tell() == 0:  # íŒŒì¼ì´ ë¹„ì–´ìˆìœ¼ë©´
            writer.writeheader()

        # ì „ì²´ í–‰ ìˆ˜ ê³„ì‚°
        rows = list(reader)
        total_rows = len(rows)
        
        # ì‹œì‘ ë¼ì¸ ì²˜ë¦¬
        if start_line > 1:
            rows = rows[start_line-1:]  # start_line-1 ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘ (0-based)
            print(f"ğŸ“ {start_line}ë²ˆì§¸ ë¼ì¸ë¶€í„° ì²˜ë¦¬ ì‹œì‘ (ì´ {len(rows)}ê°œ ë¬¸í•­)")
        
        passed_count = 0
        filtered_count = 0
        filter_reasons = {
            "validity_low": 0,
            "recommendation_remove": 0,
            "difficulty_extreme": 0,
            "hallucination": 0,
            "distractor_issues": 0,
            "structural_issues": 0,
            "semantic_distance": 0,
            "logical_gap": 0,
            "answer_validity": 0,
            "overlap": 0,
            "obvious_negative": 0,
            "factual_only": 0,
            "insufficient_grounds": 0,
            "excessive_distance": 0
        }
        
        # tqdmìœ¼ë¡œ ì§„í–‰ë„ í‘œì‹œ
        for i, row in enumerate(tqdm(rows, desc="ë¬¸í•­ í‰ê°€ ì¤‘", unit="ë¬¸í•­"), start=start_line):
            try:
                tqdm.write(f"ğŸ” Evaluating Q{i}: {row['question'][:40]}...")
                result = judge_question(row)

                if passes_filter(result, filter_reasons):
                    writer.writerow(row)
                    passed_count += 1
                    tqdm.write(f" PASSED â†’ Outputì— ì¶”ê°€ë¨")
                    if result and result.get("detailed_analysis"):
                        analysis = result["detailed_analysis"]
                        tqdm.write(f"   ğŸ“Š ë‚œì´ë„: {result.get('difficulty_score', 'N/A')}ì ")
                        tqdm.write(f"   ğŸ“ ì¢…í•©í‰ê°€: {analysis.get('overall_assessment', 'N/A')[:50]}...")
                else:
                    filtered_count += 1
                    tqdm.write(f" FILTERED OUT")
                    if result:
                        errors = result.get("errors", [])
                        if errors:
                            tqdm.write(f"    í•„í„°ë§ ì‚¬ìœ :")
                            for error in errors[:3]:  # ìµœëŒ€ 3ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
                                tqdm.write(f"      - {error.get('type', 'Unknown')}: {error.get('comment', '')[:60]}...")
                        if result.get("recommendation") == "Remove":
                            tqdm.write(f"    ê¶Œì¥ì‚¬í•­: ì œê±°")
                        elif result.get("validity") == "Low":
                            tqdm.write(f"    íƒ€ë‹¹ì„±: ë‚®ìŒ")
            except Exception as ex:
                print(f"âš ï¸ ë¬¸í•­ {i} ì²˜ë¦¬ ì˜¤ë¥˜: {ex}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ í†µê³¼ ì²˜ë¦¬
                writer.writerow(row)
                passed_count += 1
                tqdm.write(f" ERROR â†’ ì•ˆì „í•˜ê²Œ í†µê³¼ ì²˜ë¦¬ë¨")

    print(f"\n í•„í„°ë§ ì™„ë£Œ!")
    print(f"    ì´ ë¬¸í•­: {total_rows}ê°œ")
    print(f"    í†µê³¼: {passed_count}ê°œ")
    print(f"    í•„í„°ë§: {filtered_count}ê°œ")
    print(f"    ê²°ê³¼ íŒŒì¼: '{output_csv}'")
    
    print(f"\n    í•„í„°ë§ ì´ìœ ë³„ í†µê³„:")
    for reason, count in filter_reasons.items():
        if count > 0:
            print(f"   - {reason}: {count}ê°œ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë²•ë¥  MCQA ë°ì´í„°ì…‹ í•„í„°ë§")
    parser.add_argument("--batch", type=int, required=True, help="ë°°ì¹˜ ë²ˆí˜¸ (1, 2, 3, ...)")
    parser.add_argument("--start-line", type=int, default=1, help="ì‹œì‘ ë¼ì¸ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)")
    args = parser.parse_args()
    
    batch_num = args.batch
    start_line = args.start_line
    input_file = f"batch{batch_num}.csv"
    output_file = f"batch{batch_num}_filtered.csv"
    
    print(f" ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì‹œì‘")
    print(f" ì…ë ¥ íŒŒì¼: {input_file}")
    print(f" ì¶œë ¥ íŒŒì¼: {output_file}")
    print(f" ì‹œì‘ ë¼ì¸: {start_line}")
    
    filter_mcqa(input_file, output_file, start_line)
